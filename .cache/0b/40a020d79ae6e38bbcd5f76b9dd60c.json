{"id":"node_modules/@tensorflow/tfjs-converter/dist/tf-converter.esm.js","dependencies":[{"name":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/package.json","includedInParent":true,"mtime":1636789466000},{"name":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/node_modules/@tensorflow/tfjs-converter/package.json","includedInParent":true,"mtime":1636887546085},{"name":"@tensorflow/tfjs-core","loc":{"line":17,"column":1000},"parent":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/node_modules/@tensorflow/tfjs-converter/dist/tf-converter.esm.js","resolved":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/node_modules/@tensorflow/tfjs-core/dist/tf-core.esm.js"},{"name":"buffer","parent":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/node_modules/@tensorflow/tfjs-converter/dist/tf-converter.esm.js","resolved":"/Users/kmadasu/kishore/trainings/javascript-gt/gautam/poseanimator/node_modules/buffer/index.js"}],"generated":{"js":"var Buffer = require(\"buffer\").Buffer;\n\"use strict\";\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\nexports.loadGraphModel = loadGraphModel;\nexports.deregisterOp = deregisterOp;\nexports.registerOp = registerOp;\nexports.version_converter = exports.GraphModel = void 0;\n\nvar _tfjsCore = require(\"@tensorflow/tfjs-core\");\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nvar DataType,\n    SaverDef,\n    __assign = function () {\n  return (__assign = Object.assign || function (e) {\n    for (var t, a = 1, r = arguments.length; a < r; a++) for (var n in t = arguments[a]) Object.prototype.hasOwnProperty.call(t, n) && (e[n] = t[n]);\n\n    return e;\n  }).apply(this, arguments);\n};\n\nfunction __awaiter(e, t, a, r) {\n  return new (a || (a = Promise))(function (n, s) {\n    function o(e) {\n      try {\n        u(r.next(e));\n      } catch (e) {\n        s(e);\n      }\n    }\n\n    function p(e) {\n      try {\n        u(r.throw(e));\n      } catch (e) {\n        s(e);\n      }\n    }\n\n    function u(e) {\n      e.done ? n(e.value) : new a(function (t) {\n        t(e.value);\n      }).then(o, p);\n    }\n\n    u((r = r.apply(e, t || [])).next());\n  });\n}\n\nfunction __generator(e, t) {\n  var a,\n      r,\n      n,\n      s,\n      o = {\n    label: 0,\n    sent: function () {\n      if (1 & n[0]) throw n[1];\n      return n[1];\n    },\n    trys: [],\n    ops: []\n  };\n  return s = {\n    next: p(0),\n    throw: p(1),\n    return: p(2)\n  }, \"function\" == typeof Symbol && (s[Symbol.iterator] = function () {\n    return this;\n  }), s;\n\n  function p(s) {\n    return function (p) {\n      return function (s) {\n        if (a) throw new TypeError(\"Generator is already executing.\");\n\n        for (; o;) try {\n          if (a = 1, r && (n = 2 & s[0] ? r.return : s[0] ? r.throw || ((n = r.return) && n.call(r), 0) : r.next) && !(n = n.call(r, s[1])).done) return n;\n\n          switch (r = 0, n && (s = [2 & s[0], n.value]), s[0]) {\n            case 0:\n            case 1:\n              n = s;\n              break;\n\n            case 4:\n              return o.label++, {\n                value: s[1],\n                done: !1\n              };\n\n            case 5:\n              o.label++, r = s[1], s = [0];\n              continue;\n\n            case 7:\n              s = o.ops.pop(), o.trys.pop();\n              continue;\n\n            default:\n              if (!(n = (n = o.trys).length > 0 && n[n.length - 1]) && (6 === s[0] || 2 === s[0])) {\n                o = 0;\n                continue;\n              }\n\n              if (3 === s[0] && (!n || s[1] > n[0] && s[1] < n[3])) {\n                o.label = s[1];\n                break;\n              }\n\n              if (6 === s[0] && o.label < n[1]) {\n                o.label = n[1], n = s;\n                break;\n              }\n\n              if (n && o.label < n[2]) {\n                o.label = n[2], o.ops.push(s);\n                break;\n              }\n\n              n[2] && o.ops.pop(), o.trys.pop();\n              continue;\n          }\n\n          s = t.call(e, o);\n        } catch (e) {\n          s = [6, e], r = 0;\n        } finally {\n          a = n = 0;\n        }\n\n        if (5 & s[0]) throw s[1];\n        return {\n          value: s[0] ? s[1] : void 0,\n          done: !0\n        };\n      }([s, p]);\n    };\n  }\n}\n\n!function (e) {\n  e[e.DT_INVALID = 0] = \"DT_INVALID\", e[e.DT_FLOAT = 1] = \"DT_FLOAT\", e[e.DT_DOUBLE = 2] = \"DT_DOUBLE\", e[e.DT_INT32 = 3] = \"DT_INT32\", e[e.DT_UINT8 = 4] = \"DT_UINT8\", e[e.DT_INT16 = 5] = \"DT_INT16\", e[e.DT_INT8 = 6] = \"DT_INT8\", e[e.DT_STRING = 7] = \"DT_STRING\", e[e.DT_COMPLEX64 = 8] = \"DT_COMPLEX64\", e[e.DT_INT64 = 9] = \"DT_INT64\", e[e.DT_BOOL = 10] = \"DT_BOOL\", e[e.DT_QINT8 = 11] = \"DT_QINT8\", e[e.DT_QUINT8 = 12] = \"DT_QUINT8\", e[e.DT_QINT32 = 13] = \"DT_QINT32\", e[e.DT_BFLOAT16 = 14] = \"DT_BFLOAT16\", e[e.DT_FLOAT_REF = 101] = \"DT_FLOAT_REF\", e[e.DT_DOUBLE_REF = 102] = \"DT_DOUBLE_REF\", e[e.DT_INT32_REF = 103] = \"DT_INT32_REF\", e[e.DT_UINT8_REF = 104] = \"DT_UINT8_REF\", e[e.DT_INT16_REF = 105] = \"DT_INT16_REF\", e[e.DT_INT8_REF = 106] = \"DT_INT8_REF\", e[e.DT_STRING_REF = 107] = \"DT_STRING_REF\", e[e.DT_COMPLEX64_REF = 108] = \"DT_COMPLEX64_REF\", e[e.DT_INT64_REF = 109] = \"DT_INT64_REF\", e[e.DT_BOOL_REF = 110] = \"DT_BOOL_REF\", e[e.DT_QINT8_REF = 111] = \"DT_QINT8_REF\", e[e.DT_QUINT8_REF = 112] = \"DT_QUINT8_REF\", e[e.DT_QINT32_REF = 113] = \"DT_QINT32_REF\", e[e.DT_BFLOAT16_REF = 114] = \"DT_BFLOAT16_REF\";\n}(DataType || (DataType = {})), function (e) {\n  !function (e) {\n    e[e.LEGACY = 0] = \"LEGACY\", e[e.V1 = 1] = \"V1\", e[e.V2 = 2] = \"V2\";\n  }(e.CheckpointFormatVersion || (e.CheckpointFormatVersion = {}));\n}(SaverDef || (SaverDef = {}));\nvar CUSTOM_OPS = {};\n\nfunction registerOp(e, t) {\n  var a = {\n    tfOpName: e,\n    category: \"custom\",\n    inputs: [],\n    attrs: [],\n    customExecutor: t\n  };\n  CUSTOM_OPS[e] = a;\n}\n\nfunction getRegisteredOp(e) {\n  return CUSTOM_OPS[e];\n}\n\nfunction deregisterOp(e) {\n  delete CUSTOM_OPS[e];\n}\n\nfunction getParamValue(e, t, a, r) {\n  var n = t.inputParams[e];\n\n  if (n && void 0 !== n.inputIndexStart) {\n    var s = n.inputIndexStart,\n        o = 0 === n.inputIndexEnd ? void 0 : void 0 === n.inputIndexEnd ? s + 1 : n.inputIndexEnd;\n    if (\"tensor\" === n.type) return getTensor(t.inputNames[n.inputIndexStart], a, r);\n    if (\"tensors\" === n.type) return t.inputNames.slice(s, o).map(function (e) {\n      return getTensor(e, a, r);\n    });\n    var p = Array.prototype.slice.call(getTensor(t.inputNames.slice(s)[0], a, r).dataSync());\n    return \"number\" === n.type ? p[0] : p;\n  }\n\n  var u = t.attrParams[e];\n  return u && u.value;\n}\n\nfunction getTensor(e, t, a) {\n  var r = parseNodeName(e),\n      n = r[0],\n      s = r[1],\n      o = a.currentContextIds.find(function (e) {\n    return !!t[getNodeNameWithContextId(n, e)];\n  });\n  return void 0 !== o ? t[getNodeNameWithContextId(n, o)][s] : void 0;\n}\n\nfunction getTensorsForCurrentContenxt(e, t, a) {\n  return t[getNodeNameWithContextId(e, a.currentContextId)];\n}\n\nfunction getNodeNameAndIndex(e, t) {\n  var a = parseNodeName(e),\n      r = a[0],\n      n = a[1];\n  return [getNodeNameWithContextId(r, t && t.currentContextId), n];\n}\n\nfunction getNodeNameWithContextId(e, t) {\n  return t ? e + \"-\" + t : e;\n}\n\nfunction parseNodeName(e) {\n  var t = e.lastIndexOf(\":\");\n  return -1 === t ? [e, 0] : [e.substring(0, t), Number(e.substring(t + 1))];\n}\n\nfunction split$1(e, t) {\n  for (var a = [], r = 0; r < e.length; r += t) a.push(e.slice(r, r + t));\n\n  return a;\n}\n\nvar json = [{\n  tfOpName: \"Add\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AddV2\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AddN\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"BiasAdd\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sub\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"RealDiv\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Div\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"DivNoNan\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorDiv\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mul\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Maximum\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Minimum\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Pow\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"SquaredDifference\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Mod\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FloorMod\",\n  category: \"arithmetic\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    arithmetic = Object.freeze({\n  json: json\n}),\n    json$1 = [{\n  tfOpName: \"Abs\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acos\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asin\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atan2\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"y\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ceil\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ClipByValue\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"clip_value_min\",\n    name: \"clipValueMin\",\n    type: \"number\"\n  }, {\n    tfName: \"clip_value_max\",\n    name: \"clipValueMax\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Complex\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"real\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"imag\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ComplexAbs\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Cos\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Cosh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Elu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Exp\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Floor\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Imag\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"Tout\",\n    name: \"outputType\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Neg\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Real\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"Tout\",\n    name: \"outputType\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Prelu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"alpha\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Relu6\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"clipValueMin\",\n    name: \"clipValueMin\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"clipValueMax\",\n    name: \"clipValueMax\",\n    type: \"number\",\n    defaultValue: 6\n  }]\n}, {\n  tfOpName: \"Selu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sigmoid\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sin\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sinh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sqrt\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Rsqrt\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Square\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tan\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tanh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Sign\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Round\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Expm1\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Log1p\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reciprocal\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Softplus\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Asinh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Acosh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Atanh\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Erf\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Prod\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axes\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\",\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LeakyRelu\",\n  category: \"basic_math\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"alpha\",\n    name: \"alpha\",\n    type: \"number\",\n    defaultValue: .2\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    basicMath = Object.freeze({\n  json: json$1\n}),\n    json$2 = [{\n  tfOpName: \"LoopCond\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Switch\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"data\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"pred\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Merge\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Enter\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"frame_name\",\n    name: \"frameName\",\n    type: \"string\"\n  }, {\n    tfName: \"is_constant\",\n    name: \"isConstant\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Exit\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NextIteration\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"size\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape\",\n    name: \"elementShape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dynamic_size\",\n    name: \"dynamicSize\",\n    type: \"bool\"\n  }, {\n    tfName: \"clear_after_read\",\n    name: \"clearAfterRead\",\n    type: \"bool\"\n  }, {\n    tfName: \"identical_element_shapes\",\n    name: \"identicalElementShapes\",\n    type: \"bool\"\n  }, {\n    tfName: \"tensor_array_name\",\n    name: \"name\",\n    type: \"string\"\n  }]\n}, {\n  tfOpName: \"TensorArrayWriteV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"index\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayReadV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"index\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArrayGatherV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape\",\n    name: \"elementShape\",\n    type: \"shape\"\n  }]\n}, {\n  tfOpName: \"TensorArrayScatterV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArrayConcatV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"element_shape_except0\",\n    name: \"elementShapeExcept0\",\n    type: \"shape\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"TensorArraySplitV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"tensor\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"lengths\",\n    type: \"number[]\"\n  }, {\n    start: 3,\n    name: \"flowIn\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TensorArraySizeV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"flowIn\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"TensorArrayCloseV3\",\n  category: \"control\",\n  inputs: [{\n    start: 0,\n    name: \"tensorArrayId\",\n    type: \"number\"\n  }]\n}],\n    control = Object.freeze({\n  json: json$2\n}),\n    json$3 = [{\n  tfOpName: \"AvgPool\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPool\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"AvgPool3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MaxPool3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }, {\n    tfName: \"ksize\",\n    name: \"kernelSize\",\n    type: \"number[]\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Conv1D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"stride\",\n    name: \"stride\",\n    type: \"number\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NWC\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"dilation\",\n    name: \"dilation\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"Conv2D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"useCudnnOnGpu\",\n    name: \"useCudnnOnGpu\",\n    type: \"bool\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"_FusedConv2D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"explicit_paddings\",\n    name: \"explicitPaddings\",\n    type: \"number[]\",\n    defaultValue: []\n  }, {\n    tfName: \"use_cudnn_on_gpu\",\n    name: \"useCudnnOnGpu\",\n    type: \"bool\",\n    defaultValue: !0\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\",\n    defaultValue: [1, 1, 1, 1]\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }, {\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: 1e-4\n  }]\n}, {\n  tfOpName: \"Conv2DBackpropInput\",\n  category: \"convolution\",\n  inputs: [{\n    start: 2,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 0,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2d\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"input\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthwiseConv2dNative\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"input\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"FusedDepthwiseConv2dNative\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\",\n    defaultValue: [1, 1, 1, 1]\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }]\n}, {\n  tfOpName: \"Conv3D\",\n  category: \"convolution\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"filter\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"strides\",\n    name: \"strides\",\n    type: \"number[]\"\n  }, {\n    tfName: \"padding\",\n    name: \"pad\",\n    type: \"string\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    defaultValue: \"NHWC\"\n  }, {\n    tfName: \"dilations\",\n    name: \"dilations\",\n    type: \"number[]\"\n  }]\n}],\n    convolution = Object.freeze({\n  json: json$3\n}),\n    json$4 = [{\n  tfOpName: \"Fill\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }, {\n    start: 1,\n    name: \"value\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"LinSpace\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"start\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"stop\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"num\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"OneHot\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"depth\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"onValue\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    start: 3,\n    name: \"offValue\",\n    type: \"number\",\n    defaultValue: 0\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Ones\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"OnesLike\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"RandomUniform\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"minval\",\n    name: \"minval\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"maxval\",\n    name: \"maxval\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfName: \"T\",\n    name: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Range\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"start\",\n    type: \"number\"\n  }, {\n    start: 1,\n    name: \"stop\",\n    type: \"number\"\n  }, {\n    start: 2,\n    name: \"step\",\n    type: \"number\",\n    defaultValue: 0\n  }],\n  attrs: [{\n    tfName: \"Tidx\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"TruncatedNormal\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"means\",\n    name: \"mean\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"stddev\",\n    name: \"stdDev\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\"\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"T\",\n    name: \"T\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Zeros\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"shape\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ZerosLike\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Multinomial\",\n  category: \"creation\",\n  inputs: [{\n    start: 0,\n    name: \"logits\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"numSamples\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"seed\",\n    name: \"seed\",\n    type: \"number\"\n  }, {\n    tfName: \"seed2\",\n    name: \"seed2\",\n    type: \"number\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }, {\n    tfName: \"output_dtype\",\n    name: \"output_dtype\",\n    type: \"dtype\"\n  }]\n}],\n    creation = Object.freeze({\n  json: json$4\n}),\n    json$5 = [{\n  tfOpName: \"NonMaxSuppressionV2\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"NonMaxSuppressionV3\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }, {\n    start: 4,\n    name: \"scoreThreshold\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"NonMaxSuppressionV5\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scores\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"maxOutputSize\",\n    type: \"number\"\n  }, {\n    start: 3,\n    name: \"iouThreshold\",\n    type: \"number\"\n  }, {\n    start: 4,\n    name: \"scoreThreshold\",\n    type: \"number\"\n  }, {\n    start: 5,\n    name: \"softNmsSigma\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Where\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"condition\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ListDiff\",\n  category: \"dynamic\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"y\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    dynamic = Object.freeze({\n  json: json$5\n}),\n    json$6 = [{\n  tfOpName: \"TopKV2\",\n  category: \"evaluation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"k\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"sorted\",\n    name: \"sorted\",\n    type: \"bool\"\n  }]\n}],\n    evaluation = Object.freeze({\n  json: json$6\n}),\n    json$7 = [{\n  tfOpName: \"PlaceholderWithDefault\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"default\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"shape\",\n    name: \"shape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Placeholder\",\n  category: \"graph\",\n  attrs: [{\n    tfName: \"shape\",\n    name: \"shape\",\n    type: \"shape\"\n  }, {\n    tfName: \"dtype\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"Const\",\n  category: \"graph\"\n}, {\n  tfOpName: \"Identity\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"IdentityN\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"x\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Snapshot\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Rank\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Size\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"Shape\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"ShapeN\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"x\",\n    type: \"tensors\"\n  }]\n}, {\n  tfOpName: \"Print\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"data\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"message\",\n    name: \"message\",\n    type: \"string\"\n  }, {\n    tfName: \"first_n\",\n    name: \"firstN\",\n    type: \"number\",\n    notSupported: !0\n  }, {\n    tfName: \"summarize\",\n    name: \"summarize\",\n    type: \"number\",\n    defaultValue: 3\n  }]\n}, {\n  tfOpName: \"NoOp\",\n  category: \"graph\",\n  inputs: []\n}, {\n  tfOpName: \"StopGradient\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"FakeQuantWithMinMaxVars\",\n  category: \"graph\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"min\",\n    name: \"min\",\n    type: \"number\"\n  }, {\n    tfName: \"max\",\n    name: \"max\",\n    type: \"number\"\n  }]\n}],\n    graph = Object.freeze({\n  json: json$7\n}),\n    json$8 = [{\n  tfOpName: \"ResizeBilinear\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"images\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"size\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"align_corners\",\n    name: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ResizeNearestNeighbor\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"images\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"size\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"align_corners\",\n    name: \"alignCorners\",\n    type: \"bool\"\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"CropAndResize\",\n  category: \"image\",\n  inputs: [{\n    start: 0,\n    name: \"image\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"boxes\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"boxInd\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"cropSize\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"method\",\n    name: \"method\",\n    type: \"string\"\n  }, {\n    tfName: \"extrapolation_value\",\n    name: \"extrapolationValue\",\n    type: \"number\"\n  }]\n}],\n    image$1 = Object.freeze({\n  json: json$8\n}),\n    json$9 = [{\n  tfOpName: \"Equal\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"NotEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Greater\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"GreaterEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Less\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LessEqual\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalAnd\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalNot\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LogicalOr\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Select\",\n  category: \"logical\",\n  inputs: [{\n    start: 0,\n    name: \"condition\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    logical = Object.freeze({\n  json: json$9\n}),\n    json$10 = [{\n  tfOpName: \"_FusedMatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    end: 0,\n    name: \"args\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"num_args\",\n    name: \"numArgs\",\n    type: \"number\"\n  }, {\n    tfName: \"fused_ops\",\n    name: \"fusedOps\",\n    type: \"string[]\",\n    defaultValue: []\n  }, {\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: 1e-4\n  }, {\n    tfName: \"transpose_a\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"transpose_b\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"MatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"transpose_a\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"transpose_b\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"BatchMatMul\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"adj_x\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"adj_y\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"BatchMatMulV2\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"a\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"b\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"adj_x\",\n    name: \"transposeA\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"adj_y\",\n    name: \"transposeB\",\n    type: \"bool\",\n    defaultValue: !1\n  }, {\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Transpose\",\n  category: \"matrices\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"perm\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"T\",\n    name: \"dtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }]\n}],\n    matrices = Object.freeze({\n  json: json$10\n}),\n    json$11 = [{\n  tfOpName: \"FusedBatchNorm\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FusedBatchNormV2\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"FusedBatchNormV3\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"scale\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"offset\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"mean\",\n    type: \"tensor\"\n  }, {\n    start: 4,\n    name: \"variance\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"epsilon\",\n    name: \"epsilon\",\n    type: \"number\",\n    defaultValue: .001\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"LRN\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"depth_radius\",\n    name: \"radius\",\n    type: \"number\",\n    defaultValue: 5\n  }, {\n    tfName: \"bias\",\n    name: \"bias\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"alpha\",\n    name: \"alpha\",\n    type: \"number\",\n    defaultValue: 1\n  }, {\n    tfName: \"beta\",\n    name: \"beta\",\n    type: \"number\",\n    defaultValue: .5\n  }]\n}, {\n  tfOpName: \"Softmax\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"LogSoftmax\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  category: \"normalization\",\n  inputs: [{\n    start: 0,\n    name: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"defaultValue\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !0,\n    notSupported: !0\n  }]\n}],\n    normalization = Object.freeze({\n  json: json$11\n}),\n    json$12 = [{\n  tfOpName: \"Max\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Mean\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Min\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Sum\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"All\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"Any\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}, {\n  tfOpName: \"ArgMax\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"ArgMin\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Prod\",\n  category: \"reduction\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"keep_dims\",\n    name: \"keepDims\",\n    type: \"bool\"\n  }]\n}],\n    reduction = Object.freeze({\n  json: json$12\n}),\n    json$13 = [{\n  tfOpName: \"ConcatV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    end: -1,\n    name: \"tensors\",\n    type: \"tensors\"\n  }, {\n    start: -1,\n    name: \"axis\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"N\",\n    name: \"n\",\n    type: \"number\",\n    defaultValue: 2\n  }]\n}, {\n  tfOpName: \"Concat\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 1,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }, {\n    start: 0,\n    name: \"axis\",\n    type: \"number\"\n  }],\n  attrs: [{\n    tfName: \"N\",\n    name: \"n\",\n    type: \"number\",\n    defaultValue: 2\n  }]\n}, {\n  tfOpName: \"GatherV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Gather\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Reverse\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"dims\",\n    type: \"bool\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"ReverseV2\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Slice\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"begin\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"size\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"StridedSlice\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"begin\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"end\",\n    type: \"number[]\"\n  }, {\n    start: 3,\n    name: \"strides\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"begin_mask\",\n    name: \"beginMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"end_mask\",\n    name: \"endMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"new_axis_mask\",\n    name: \"newAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"ellipsis_mask\",\n    name: \"ellipsisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"shrink_axis_mask\",\n    name: \"shrinkAxisMask\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Pack\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    end: 0,\n    name: \"tensors\",\n    type: \"tensors\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Unpack\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"tensor\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    tfName: \"num\",\n    name: \"num\",\n    type: \"number\",\n    defaultValue: 0,\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"Tile\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"reps\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Split\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }, {\n    start: 1,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"num_split\",\n    name: \"numOrSizeSplits\",\n    type: \"number\",\n    defaultValue: 1\n  }]\n}, {\n  tfOpName: \"SplitV\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"numOrSizeSplits\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"axis\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"ScatterNd\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"indices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"values\",\n    type: \"tensor\"\n  }, {\n    start: 2,\n    name: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"GatherNd\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"indices\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"SparseToDense\",\n  category: \"slice_join\",\n  inputs: [{\n    start: 0,\n    name: \"sparseIndices\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"outputShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"sparseValues\",\n    type: \"tensor\"\n  }, {\n    start: 3,\n    name: \"defaultValue\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"validate_indices\",\n    name: \"validateIndices\",\n    type: \"bool\",\n    defaultValue: !1,\n    notSupported: !0\n  }]\n}],\n    sliceJoin = Object.freeze({\n  json: json$13\n}),\n    json$14 = [{\n  tfOpName: \"FFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"IFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }]\n}, {\n  tfOpName: \"RFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"fft_length\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}, {\n  tfOpName: \"IRFFT\",\n  category: \"spectral\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"fft_length\",\n    type: \"number\",\n    notSupported: !0\n  }]\n}],\n    spectral = Object.freeze({\n  json: json$14\n}),\n    json$15 = [{\n  tfOpName: \"Cast\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"SrcT\",\n    name: \"sdtype\",\n    type: \"dtype\",\n    notSupported: !0\n  }, {\n    tfName: \"DstT\",\n    name: \"dtype\",\n    type: \"dtype\"\n  }]\n}, {\n  tfOpName: \"ExpandDims\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"axis\",\n    type: \"number\"\n  }]\n}, {\n  tfOpName: \"Pad\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"padding\",\n    type: \"number[]\"\n  }],\n  attrs: [{\n    tfName: \"constant_value\",\n    name: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"PadV2\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"padding\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"constantValue\",\n    type: \"number\",\n    defaultValue: 0\n  }]\n}, {\n  tfOpName: \"Reshape\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"shape\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"Squeeze\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"axis\",\n    tfDeprecatedName: \"squeeze_dims\",\n    name: \"axis\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"SpaceToBatchND\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"paddings\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"BatchToSpaceND\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }, {\n    start: 1,\n    name: \"blockShape\",\n    type: \"number[]\"\n  }, {\n    start: 2,\n    name: \"crops\",\n    type: \"number[]\"\n  }]\n}, {\n  tfOpName: \"DepthToSpace\",\n  category: \"transformation\",\n  inputs: [{\n    start: 0,\n    name: \"x\",\n    type: \"tensor\"\n  }],\n  attrs: [{\n    tfName: \"block_size\",\n    name: \"blockSize\",\n    type: \"number\"\n  }, {\n    tfName: \"data_format\",\n    name: \"dataFormat\",\n    type: \"string\"\n  }]\n}],\n    transformation = Object.freeze({\n  json: json$15\n}),\n    OperationMapper = function () {\n  function e() {\n    var e = [arithmetic, basicMath, control, convolution, creation, dynamic, evaluation, logical, image$1, graph, matrices, normalization, reduction, sliceJoin, spectral, transformation],\n        t = [].concat.apply([], e.map(function (e) {\n      return e.json;\n    }));\n    this.opMappers = t.reduce(function (e, t) {\n      return e[t.tfOpName] = t, e;\n    }, {});\n  }\n\n  return Object.defineProperty(e, \"Instance\", {\n    get: function () {\n      return this._instance || (this._instance = new this());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.transformGraph = function (e, t) {\n    var a = this;\n    void 0 === t && (t = {});\n    var r = [],\n        n = [],\n        s = e.node.reduce(function (e, t) {\n      return e[t.name] = a.mapNode(t), t.op.startsWith(\"Placeholder\") && r.push(e[t.name]), \"Const\" === t.op && n.push(e[t.name]), e;\n    }, {}),\n        o = [],\n        p = [],\n        u = {},\n        i = {};\n    null != t && (u = this.mapSignatureEntries(t.inputs), i = this.mapSignatureEntries(t.outputs));\n    var m = Object.keys(s);\n    return m.forEach(function (e) {\n      var t = s[e];\n      t.inputNames.forEach(function (e) {\n        var a = getNodeNameAndIndex(e)[0];\n        t.inputs.push(s[a]), s[a].children.push(t);\n      });\n    }), 0 === Object.keys(i).length ? m.forEach(function (e) {\n      var t = s[e];\n      0 === t.children.length && p.push(t);\n    }) : Object.keys(i).forEach(function (e) {\n      var t = getNodeNameAndIndex(e)[0],\n          a = s[t];\n      null != a && (a.signatureKey = i[e], p.push(a));\n    }), Object.keys(u).length > 0 ? Object.keys(u).forEach(function (e) {\n      var t = getNodeNameAndIndex(e)[0],\n          a = s[t];\n      a && (a.signatureKey = u[e], o.push(a));\n    }) : o = r, {\n      nodes: s,\n      inputs: o,\n      outputs: p,\n      weights: n,\n      placeholders: r,\n      signature: t\n    };\n  }, e.prototype.mapSignatureEntries = function (e) {\n    return Object.keys(e || {}).reduce(function (t, a) {\n      return t[e[a].name] = a, t;\n    }, {});\n  }, e.prototype.mapNode = function (e) {\n    var t = getRegisteredOp(e.op) || this.opMappers[e.op] || {};\n    null == e.attr && (e.attr = {});\n    var a = {\n      name: e.name,\n      op: e.op,\n      category: t.category,\n      inputNames: (e.input || []).map(function (e) {\n        return e.startsWith(\"^\") ? e.substr(1) : e;\n      }),\n      inputs: [],\n      children: [],\n      inputParams: {},\n      attrParams: {},\n      rawAttrs: e.attr\n    };\n    return null != t.inputs && (a.inputParams = t.inputs.reduce(function (e, t) {\n      return e[t.name] = {\n        type: t.type,\n        inputIndexStart: t.start,\n        inputIndexEnd: t.end\n      }, e;\n    }, {})), null != t.attrs && (a.attrParams = t.attrs.reduce(function (t, a) {\n      var r = a.type,\n          n = void 0;\n\n      switch (a.type) {\n        case \"string\":\n          void 0 === (n = getStringParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getStringParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"string[]\":\n          void 0 === (n = getStringArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getStringArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"number\":\n          void 0 === (n = getNumberParam(e.attr, a.tfName, a.defaultValue || 0)) && a.tfDeprecatedName && (n = getNumberParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"number[]\":\n          void 0 === (n = getNumericArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getNumericArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"bool\":\n          void 0 === (n = getBoolParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getBoolParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"bool[]\":\n          void 0 === (n = getBoolArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getBoolArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"shape\":\n          void 0 === (n = getTensorShapeParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getTensorShapeParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"shape[]\":\n          void 0 === (n = getTensorShapeArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getTensorShapeArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"dtype\":\n          void 0 === (n = getDtypeParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getDtypeParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"dtype[]\":\n          void 0 === (n = getDtypeArrayParam(e.attr, a.tfName, a.defaultValue)) && a.tfDeprecatedName && (n = getDtypeArrayParam(e.attr, a.tfDeprecatedName, a.defaultValue));\n          break;\n\n        case \"tensor\":\n        case \"tensors\":\n          break;\n\n        default:\n          throw new Error(\"Unsupported param type: \" + a.type + \" for op: \" + e.op);\n      }\n\n      return t[a.name] = {\n        value: n,\n        type: r\n      }, t;\n    }, {})), a;\n  }, e;\n}();\n\nfunction decodeBase64(e) {\n  var t = (0, _tfjsCore.env)().global;\n  if (void 0 !== t.atob) return t.atob(e);\n  if (\"undefined\" != typeof Buffer) return new Buffer(e, \"base64\").toString();\n  throw new Error(\"Unable to decode base64 in this environment. Missing built-in atob() or Buffer()\");\n}\n\nfunction parseStringParam(e, t) {\n  var a = Array.isArray(e) ? String.fromCharCode.apply(null, e) : decodeBase64(e);\n  return t ? a : a.toLowerCase();\n}\n\nfunction getStringParam(e, t, a, r) {\n  void 0 === r && (r = !1);\n  var n = e[t];\n  return null != n ? parseStringParam(n.s, r) : a;\n}\n\nfunction getBoolParam(e, t, a) {\n  var r = e[t];\n  return r ? r.b : a;\n}\n\nfunction getNumberParam(e, t, a) {\n  var r = e[t] || {},\n      n = null != r.i ? r.i : null != r.f ? r.f : a;\n  return \"number\" == typeof n ? n : parseInt(n, 10);\n}\n\nfunction parseDtypeParam(e) {\n  switch (\"string\" == typeof e && (e = DataType[e]), e) {\n    case DataType.DT_FLOAT:\n      return \"float32\";\n\n    case DataType.DT_INT32:\n    case DataType.DT_INT64:\n      return \"int32\";\n\n    case DataType.DT_BOOL:\n      return \"bool\";\n\n    case DataType.DT_DOUBLE:\n      return \"float32\";\n\n    case DataType.DT_STRING:\n      return \"string\";\n\n    default:\n      return null;\n  }\n}\n\nfunction getDtypeParam(e, t, a) {\n  var r = e[t];\n  return r && r.type ? parseDtypeParam(r.type) : a;\n}\n\nfunction getDtypeArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.type ? r.list.type.map(function (e) {\n    return parseDtypeParam(e);\n  }) : a;\n}\n\nfunction parseTensorShapeParam(e) {\n  if (!e.unknownRank) return null != e.dim ? e.dim.map(function (e) {\n    return \"number\" == typeof e.size ? e.size : parseInt(e.size, 10);\n  }) : [];\n}\n\nfunction getTensorShapeParam(e, t, a) {\n  var r = e[t];\n  return r && r.shape ? parseTensorShapeParam(r.shape) : a;\n}\n\nfunction getNumericArrayParam(e, t, a) {\n  var r = e[t];\n  return r ? ((r.list.f && r.list.f.length ? r.list.f : r.list.i) || []).map(function (e) {\n    return \"number\" == typeof e ? e : parseInt(e, 10);\n  }) : a;\n}\n\nfunction getStringArrayParam(e, t, a, r) {\n  void 0 === r && (r = !1);\n  var n = e[t];\n  return n && n.list && n.list.s ? n.list.s.map(function (e) {\n    return parseStringParam(e, r);\n  }) : a;\n}\n\nfunction getTensorShapeArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.shape ? r.list.shape.map(function (e) {\n    return parseTensorShapeParam(e);\n  }) : a;\n}\n\nfunction getBoolArrayParam(e, t, a) {\n  var r = e[t];\n  return r && r.list && r.list.b ? r.list.b : a;\n}\n\nvar NodeValueImpl = function () {\n  function e(e, t, a) {\n    var r = this;\n    this.node = e, this.tensorMap = t, this.context = a, this.inputs = [], this.attrs = {}, this.inputs = e.inputNames.map(function (e) {\n      return r.getInput(e);\n    }), null != e.rawAttrs && (this.attrs = Object.keys(e.rawAttrs).reduce(function (e, t) {\n      return e[t] = r.getAttr(t), e;\n    }, {}));\n  }\n\n  return e.prototype.getInput = function (e) {\n    return getTensor(e, this.tensorMap, this.context);\n  }, e.prototype.getAttr = function (e, t) {\n    var a = this.node.rawAttrs[e];\n    if (null != a.tensor) return getTensor(e, this.tensorMap, this.context);\n    if (null != a.i || null != a.f) return getNumberParam(this.node.rawAttrs, e, t);\n    if (null != a.s) return getStringParam(this.node.rawAttrs, e, t);\n    if (null != a.b) return getBoolParam(this.node.rawAttrs, e, t);\n    if (null != a.shape) return getTensorShapeParam(this.node.rawAttrs, e, t);\n    if (null != a.type) return getDtypeParam(this.node.rawAttrs, e, t);\n\n    if (null != a.list) {\n      if (null != a.list.i || null != a.list.f) return getNumericArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.s) return getStringArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.shape) return getTensorShapeArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.b) return getBoolArrayParam(this.node.rawAttrs, e, t);\n      if (null != a.list.type) return getDtypeArrayParam(this.node.rawAttrs, e, t);\n    }\n\n    return t;\n  }, e;\n}(),\n    executeOp = function (e, t, a) {\n  switch (e.op) {\n    case \"BiasAdd\":\n    case \"AddV2\":\n    case \"Add\":\n      return [(0, _tfjsCore.add)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"AddN\":\n      return [(0, _tfjsCore.addN)(getParamValue(\"tensors\", e, t, a))];\n\n    case \"FloorMod\":\n    case \"Mod\":\n      return [(0, _tfjsCore.mod)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Mul\":\n      return [(0, _tfjsCore.mul)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"RealDiv\":\n    case \"Div\":\n      return [(0, _tfjsCore.div)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"DivNoNan\":\n      return [(0, _tfjsCore.divNoNan)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"FloorDiv\":\n      return [(0, _tfjsCore.floorDiv)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Sub\":\n      return [(0, _tfjsCore.sub)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Minimum\":\n      return [(0, _tfjsCore.minimum)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Maximum\":\n      return [(0, _tfjsCore.maximum)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Pow\":\n      return [(0, _tfjsCore.pow)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"SquaredDifference\":\n      return [(0, _tfjsCore.squaredDifference)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$1 = function (e, t, a) {\n  switch (e.op) {\n    case \"Abs\":\n    case \"ComplexAbs\":\n      return [(0, _tfjsCore.abs)(getParamValue(\"x\", e, t, a))];\n\n    case \"Acos\":\n      return [(0, _tfjsCore.acos)(getParamValue(\"x\", e, t, a))];\n\n    case \"Acosh\":\n      return [(0, _tfjsCore.acosh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Asin\":\n      return [(0, _tfjsCore.asin)(getParamValue(\"x\", e, t, a))];\n\n    case \"Asinh\":\n      return [(0, _tfjsCore.asinh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Atan\":\n      return [(0, _tfjsCore.atan)(getParamValue(\"x\", e, t, a))];\n\n    case \"Atan2\":\n      return [(0, _tfjsCore.atan2)(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n    case \"Atanh\":\n      return [(0, _tfjsCore.atanh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Ceil\":\n      return [(0, _tfjsCore.ceil)(getParamValue(\"x\", e, t, a))];\n\n    case \"Complex\":\n      return [(0, _tfjsCore.complex)(getParamValue(\"real\", e, t, a), getParamValue(\"imag\", e, t, a))];\n\n    case \"Cos\":\n      return [(0, _tfjsCore.cos)(getParamValue(\"x\", e, t, a))];\n\n    case \"Cosh\":\n      return [(0, _tfjsCore.cosh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Elu\":\n      return [(0, _tfjsCore.elu)(getParamValue(\"x\", e, t, a))];\n\n    case \"Erf\":\n      return [(0, _tfjsCore.erf)(getParamValue(\"x\", e, t, a))];\n\n    case \"Exp\":\n      return [(0, _tfjsCore.exp)(getParamValue(\"x\", e, t, a))];\n\n    case \"Expm1\":\n      return [(0, _tfjsCore.expm1)(getParamValue(\"x\", e, t, a))];\n\n    case \"Floor\":\n      return [(0, _tfjsCore.floor)(getParamValue(\"x\", e, t, a))];\n\n    case \"Log\":\n      return [(0, _tfjsCore.log)(getParamValue(\"x\", e, t, a))];\n\n    case \"Log1p\":\n      return [(0, _tfjsCore.log1p)(getParamValue(\"x\", e, t, a))];\n\n    case \"Imag\":\n      return [(0, _tfjsCore.imag)(getParamValue(\"x\", e, t, a))];\n\n    case \"Neg\":\n      return [(0, _tfjsCore.neg)(getParamValue(\"x\", e, t, a))];\n\n    case \"Reciprocal\":\n      return [(0, _tfjsCore.reciprocal)(getParamValue(\"x\", e, t, a))];\n\n    case \"Real\":\n      return [(0, _tfjsCore.real)(getParamValue(\"x\", e, t, a))];\n\n    case \"Relu\":\n      return [(0, _tfjsCore.relu)(getParamValue(\"x\", e, t, a))];\n\n    case \"Round\":\n      return [(0, _tfjsCore.round)(getParamValue(\"x\", e, t, a))];\n\n    case \"Selu\":\n      return [(0, _tfjsCore.selu)(getParamValue(\"x\", e, t, a))];\n\n    case \"Sigmoid\":\n      return [(0, _tfjsCore.sigmoid)(getParamValue(\"x\", e, t, a))];\n\n    case \"Sin\":\n      return [(0, _tfjsCore.sin)(getParamValue(\"x\", e, t, a))];\n\n    case \"Sign\":\n      return [(0, _tfjsCore.sign)(getParamValue(\"x\", e, t, a))];\n\n    case \"Sinh\":\n      return [(0, _tfjsCore.sinh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Softplus\":\n      return [(0, _tfjsCore.softplus)(getParamValue(\"x\", e, t, a))];\n\n    case \"Sqrt\":\n      return [(0, _tfjsCore.sqrt)(getParamValue(\"x\", e, t, a))];\n\n    case \"Square\":\n      return [(0, _tfjsCore.square)(getParamValue(\"x\", e, t, a))];\n\n    case \"Tanh\":\n      return [(0, _tfjsCore.tanh)(getParamValue(\"x\", e, t, a))];\n\n    case \"Tan\":\n      return [(0, _tfjsCore.tan)(getParamValue(\"x\", e, t, a))];\n\n    case \"Relu6\":\n    case \"ClipByValue\":\n      return [(0, _tfjsCore.clipByValue)(getParamValue(\"x\", e, t, a), getParamValue(\"clipValueMin\", e, t, a), getParamValue(\"clipValueMax\", e, t, a))];\n\n    case \"Rsqrt\":\n      return [(0, _tfjsCore.rsqrt)(getTensor(e.inputNames[0], t, a))];\n\n    case \"Prod\":\n      return [(0, _tfjsCore.prod)(getParamValue(\"x\", e, t, a), getParamValue(\"axes\", e, t, a))];\n\n    case \"LeakyRelu\":\n      return [(0, _tfjsCore.leakyRelu)(getParamValue(\"x\", e, t, a), getParamValue(\"alpha\", e, t, a))];\n\n    case \"Prelu\":\n      return [(0, _tfjsCore.prelu)(getParamValue(\"x\", e, t, a), getParamValue(\"alpha\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    TensorArray = function () {\n  function e(t, a, r, n, s, o, p) {\n    this.name = t, this.dtype = a, this.maxSize = r, this.elementShape = n, this.identicalElementShapes = s, this.dynamicSize = o, this.clearAfterRead = p, this.tensors = [], this.closed_ = !1, this.id = e.nextId++;\n  }\n\n  return Object.defineProperty(e.prototype, \"closed\", {\n    get: function () {\n      return this.closed_;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.clearAndClose = function () {\n    this.tensors.forEach(function (e) {\n      return e.tensor.dispose();\n    }), this.tensors = [], this.closed_ = !0;\n  }, e.prototype.size = function () {\n    return this.tensors.length;\n  }, e.prototype.read = function (e) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || e >= this.tensors.length) throw new Error(\"Tried to read from index \" + e + \", but array size is: \" + this.tensors.length);\n    var t = this.tensors[e];\n    if (t.cleared) throw new Error(\"TensorArray \" + this.name + \": Could not read index \" + e + \" twice because it was cleared after a previous read (perhaps try setting clear_after_read = false?).\");\n    return this.clearAfterRead && (t.cleared = !0), t.read = !0, t.tensor;\n  }, e.prototype.readMany = function (e) {\n    var t = this;\n    return e.map(function (e) {\n      return t.read(e);\n    });\n  }, e.prototype.write = function (e, t) {\n    if (this.closed_) throw new Error(\"TensorArray \" + this.name + \" has already been closed.\");\n    if (e < 0 || !this.dynamicSize && e >= this.maxSize) throw new Error(\"Tried to write to index \" + e + \", but array is not resizeable and size is: \" + this.maxSize);\n    var a = this.tensors[e] || {};\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \",\\n          because the value dtype is \" + t.dtype + \", but TensorArray dtype is \" + this.dtype + \".\");\n    if (0 !== this.size() || null != this.elementShape && 0 !== this.elementShape.length || (this.elementShape = t.shape), this.assertShapesMatchAllowUndefinedSize(this.elementShape, t.shape, \"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \".\"), a && a.read) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been read.\");\n    if (a && a.written) throw new Error(\"TensorArray \" + this.name + \": Could not write to TensorArray index \" + e + \", because it has already been written.\");\n    a.tensor = t, a.written = !0, this.tensors[e] = a;\n  }, e.prototype.writeMany = function (e, t) {\n    var a = this;\n    if (e.length !== t.length) throw new Error(\"TensorArray \" + this.name + \": could not write multiple tensors,because the index size: \" + e.length + \" is not the same as tensors size: \" + t.length + \".\");\n    e.forEach(function (e, r) {\n      return a.write(e, t[r]);\n    });\n  }, e.prototype.gather = function (e, t) {\n    if (t && t !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but gather requested dtype \" + t);\n\n    if (!e) {\n      e = [];\n\n      for (var a = 0; a < this.size(); a++) e.push(a);\n    }\n\n    if (0 === e.length) return (0, _tfjsCore.tensor)([], [0].concat(this.elementShape));\n    var r = this.readMany(e);\n    return this.assertShapesMatchAllowUndefinedSize(this.elementShape, r[0].shape, \"TensorArray shape mismatch: \"), (0, _tfjsCore.stack)(r, 0);\n  }, e.prototype.concat = function (e) {\n    if (e && e !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but concat requested dtype \" + e);\n    if (0 === this.size()) return (0, _tfjsCore.tensor)([], [0].concat(this.elementShape));\n\n    for (var t = [], a = 0; a < this.size(); a++) t.push(a);\n\n    var r = this.readMany(t);\n    return this.assertShapesMatchAllowUndefinedSize(this.elementShape, r[0].shape, \"TensorArray shape mismatch: tensor array shape (\" + this.elementShape + \") vs first tensor shape (\" + r[0].shape + \")\"), (0, _tfjsCore.concat)(r, 0);\n  }, e.prototype.scatter = function (e, t) {\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    if (e.length !== t.shape[0]) throw new Error(\"Expected len(indices) == tensor.shape[0], but saw: \" + e.length + \" vs. \" + t.shape[0]);\n    var a = Math.max.apply(Math, e);\n    if (!this.dynamicSize && a >= this.maxSize) throw new Error(\"Max index must be < array size (\" + a + \"  vs. \" + this.maxSize + \")\");\n    this.writeMany(e, (0, _tfjsCore.unstack)(t, 0));\n  }, e.prototype.split = function (e, t) {\n    var a = this;\n    if (t.dtype !== this.dtype) throw new Error(\"TensorArray dtype is \" + this.dtype + \" but tensor has dtype \" + t.dtype);\n    var r = 0,\n        n = e.map(function (e) {\n      return r += e;\n    });\n    if (r !== t.shape[0]) throw new Error(\"Expected sum of lengths to be equal to\\n          tensor.shape[0], but sum of lengths is\\n        \" + r + \", and tensor's shape is: \" + t.shape);\n    if (!this.dynamicSize && e.length !== this.maxSize) throw new Error(\"TensorArray's size is not equal to the size of lengths (\" + this.maxSize + \" vs. \" + e.length + \"), and the TensorArray is not marked as dynamically resizeable\");\n    var s = 0 === r ? 0 : t.size / r,\n        o = [];\n    (0, _tfjsCore.tidy)(function () {\n      t = t.reshape([1, r, s]);\n\n      for (var p = 0; p < e.length; ++p) {\n        var u = [0, 0 === p ? 0 : n[p - 1], 0],\n            i = [1, e[p], s];\n        o[p] = (0, _tfjsCore.slice)(t, u, i).reshape(a.elementShape);\n      }\n\n      return o;\n    });\n\n    for (var p = [], u = 0; u < e.length; u++) p[u] = u;\n\n    this.writeMany(p, o);\n  }, e.prototype.assertShapesMatchAllowUndefinedSize = function (e, t, a) {\n    void 0 === a && (a = \"\"), _tfjsCore.util.assert(this.shapesEqualAllowUndefinedSize(e, t), function () {\n      return a + \" Shapes \" + e + \" and \" + t + \" must match\";\n    });\n  }, e.prototype.shapesEqualAllowUndefinedSize = function (e, t) {\n    if (e.length !== t.length) return !1;\n\n    for (var a = 0; a < e.length; a++) if (-1 !== e[a] && -1 !== t[a] && e[a] !== t[a]) return !1;\n\n    return !0;\n  }, e.nextId = 0, e;\n}(),\n    _this = void 0,\n    executeOp$2 = function (e, t, a) {\n  return __awaiter(_this, void 0, void 0, function () {\n    var r, n, s, o, p, u, i, m, l, c, d, y, f, g, h, N, x, V, b, P, T, v, O, S, _, w, A, D, E, I, C, M, k, F, z;\n\n    return __generator(this, function (j) {\n      switch (j.label) {\n        case 0:\n          switch (e.op) {\n            case \"LoopCond\":\n              return [3, 1];\n\n            case \"Switch\":\n              return [3, 2];\n\n            case \"Merge\":\n              return [3, 4];\n\n            case \"Enter\":\n              return [3, 5];\n\n            case \"Exit\":\n              return [3, 6];\n\n            case \"NextIteration\":\n              return [3, 7];\n\n            case \"TensorArrayV3\":\n              return [3, 8];\n\n            case \"TensorArrayWriteV3\":\n              return [3, 9];\n\n            case \"TensorArrayReadV3\":\n              return [3, 10];\n\n            case \"TensorArrayGatherV3\":\n              return [3, 11];\n\n            case \"TensorArrayScatterV3\":\n              return [3, 12];\n\n            case \"TensorArrayConcatV3\":\n              return [3, 13];\n\n            case \"TensorArraySplitV3\":\n              return [3, 14];\n\n            case \"TensorArraySizeV3\":\n              return [3, 15];\n\n            case \"TensorArrayCloseV3\":\n              return [3, 16];\n          }\n\n          return [3, 17];\n\n        case 1:\n          return [2, [getParamValue(\"pred\", e, t, a).clone()]];\n\n        case 2:\n          return r = getParamValue(\"pred\", e, t, a), n = getParamValue(\"data\", e, t, a), [4, r.data()];\n\n        case 3:\n          return [2, j.sent()[0] ? [void 0, n.clone()] : [n.clone(), void 0]];\n\n        case 4:\n          return [2, (s = e.inputNames.find(function (e) {\n            return void 0 !== getTensor(e, t, a);\n          })) ? [getTensor(s, t, a).clone()] : void 0];\n\n        case 5:\n          return o = getParamValue(\"frameName\", e, t, a), p = getParamValue(\"tensor\", e, t, a), a.enterFrame(o), [2, [p.clone()]];\n\n        case 6:\n          return u = getParamValue(\"tensor\", e, t, a), a.exitFrame(), [2, [u.clone()]];\n\n        case 7:\n          return i = getParamValue(\"tensor\", e, t, a), a.nextIteration(), [2, [i.clone()]];\n\n        case 8:\n          return m = getParamValue(\"size\", e, t, a), l = getParamValue(\"dtype\", e, t, a), c = getParamValue(\"elementShape\", e, t, a), d = getParamValue(\"dynamicSize\", e, t, a), y = getParamValue(\"clearAfterRead\", e, t, a), f = getParamValue(\"identicalElementShapes\", e, t, a), g = getParamValue(\"name\", e, t, a), h = new TensorArray(g, l, m, c, f, d, y), a.addTensorArray(h), [2, [(0, _tfjsCore.scalar)(h.id), (0, _tfjsCore.scalar)(1)]];\n\n        case 9:\n          return N = getParamValue(\"tensorArrayId\", e, t, a), x = getParamValue(\"index\", e, t, a), V = getParamValue(\"tensor\", e, t, a), a.getTensorArray(N).write(x, V), [2, [(0, _tfjsCore.scalar)(1)]];\n\n        case 10:\n          return b = getParamValue(\"tensorArrayId\", e, t, a), P = getParamValue(\"index\", e, t, a), [2, [a.getTensorArray(b).read(P)]];\n\n        case 11:\n          return T = getParamValue(\"tensorArrayId\", e, t, a), v = getParamValue(\"indices\", e, t, a), O = getParamValue(\"dtype\", e, t, a), [2, [a.getTensorArray(T).gather(v, O)]];\n\n        case 12:\n          return S = getParamValue(\"tensorArrayId\", e, t, a), _ = getParamValue(\"indices\", e, t, a), w = getParamValue(\"tensor\", e, t, a), a.getTensorArray(S).scatter(_, w), [2, [(0, _tfjsCore.scalar)(1)]];\n\n        case 13:\n          return A = getParamValue(\"tensorArrayId\", e, t, a), D = a.getTensorArray(A), E = getParamValue(\"dtype\", e, t, a), [2, [D.concat(E)]];\n\n        case 14:\n          return I = getParamValue(\"tensorArrayId\", e, t, a), C = getParamValue(\"tensor\", e, t, a), M = getParamValue(\"lengths\", e, t, a), a.getTensorArray(I).split(M, C), [2, [(0, _tfjsCore.scalar)(1)]];\n\n        case 15:\n          return k = getParamValue(\"tensorArrayId\", e, t, a), F = a.getTensorArray(k), [2, [(0, _tfjsCore.scalar)(F.size(), \"int32\")]];\n\n        case 16:\n          return z = getParamValue(\"tensorArrayId\", e, t, a), a.getTensorArray(z).clearAndClose(), [2, [(0, _tfjsCore.scalar)(0)]];\n\n        case 17:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n},\n    executeOp$3 = function (e, t, a) {\n  switch (e.op) {\n    case \"Conv1D\":\n      var r = getParamValue(\"stride\", e, t, a),\n          n = getParamValue(\"pad\", e, t, a),\n          s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(),\n          o = getParamValue(\"dilation\", e, t, a);\n      return [(0, _tfjsCore.conv1d)(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), r, n, s, o)];\n\n    case \"Conv2D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      var p = getParamValue(\"dilations\", e, t, a);\n      return [(0, _tfjsCore.conv2d)(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, s, [p[1], p[2]])];\n\n    case \"_FusedConv2D\":\n    case \"FusedDepthwiseConv2dNative\":\n      var u = getParamValue(\"fusedOps\", e, t, a),\n          i = u[0],\n          m = u[1],\n          l = \"biasadd\" === i,\n          c = \"prelu\" === m,\n          d = \"fusedbatchnorm\" === i,\n          y = getParamValue(\"numArgs\", e, t, a);\n\n      if (l) {\n        if (c && 2 !== y) throw new Error(\"FusedConv2d and DepthwiseConv2d with BiasAdd and Prelu must have two extra arguments: bias and alpha.\");\n        if (!c && 1 !== y) throw new Error(\"FusedConv2d and DepthwiseConv2d with BiasAdd must have one extra argument: bias.\");\n      }\n\n      if (d) throw new Error(\"FusedConv2d and DepthwiseConv2d with FusedBatchNorm is not supported.\");\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(), p = getParamValue(\"dilations\", e, t, a);\n      var f = getParamValue(\"args\", e, t, a),\n          g = f[0],\n          h = f[1];\n      return [(\"_FusedConv2D\" === e.op ? _tfjsCore.fused.conv2d : _tfjsCore.fused.depthwiseConv2d)({\n        x: getParamValue(\"x\", e, t, a),\n        filter: getParamValue(\"filter\", e, t, a),\n        strides: [r[1], r[2]],\n        pad: n,\n        dataFormat: s,\n        dilations: [p[1], p[2]],\n        bias: g,\n        activation: m,\n        preluActivationWeights: h\n      })];\n\n    case \"Conv2DBackpropInput\":\n    case \"Conv2dTranspose\":\n      var N = getParamValue(\"outputShape\", e, t, a);\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      return [(0, _tfjsCore.conv2dTranspose)(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), N, [r[1], r[2]], n)];\n\n    case \"DepthwiseConv2dNative\":\n    case \"DepthwiseConv2d\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), p = getParamValue(\"dilations\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [(0, _tfjsCore.depthwiseConv2d)(getParamValue(\"input\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2]], n, s, [p[1], p[2]])];\n\n    case \"Conv3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), s = getParamValue(\"dataFormat\", e, t, a).toUpperCase(), p = getParamValue(\"dilations\", e, t, a);\n      return [(0, _tfjsCore.conv3d)(getParamValue(\"x\", e, t, a), getParamValue(\"filter\", e, t, a), [r[1], r[2], r[3]], n, s, [p[1], p[2], p[3]])];\n\n    case \"AvgPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a);\n      var x = getParamValue(\"kernelSize\", e, t, a);\n      return [(0, _tfjsCore.avgPool)(getParamValue(\"x\", e, t, a), [x[1], x[2]], [r[1], r[2]], n)];\n\n    case \"MaxPool\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [(0, _tfjsCore.maxPool)(getParamValue(\"x\", e, t, a), [x[1], x[2]], [r[1], r[2]], n)];\n\n    case \"AvgPool3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [(0, _tfjsCore.avgPool3d)(getParamValue(\"x\", e, t, a), [x[1], x[2], x[3]], [r[1], r[2], r[3]], n)];\n\n    case \"MaxPool3D\":\n      r = getParamValue(\"strides\", e, t, a), n = getParamValue(\"pad\", e, t, a), x = getParamValue(\"kernelSize\", e, t, a);\n      return [(0, _tfjsCore.maxPool3d)(getParamValue(\"x\", e, t, a), [x[1], x[2], x[3]], [r[1], r[2], r[3]], n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$4 = function (e, t, a) {\n  switch (e.op) {\n    case \"Fill\":\n      var r = getParamValue(\"shape\", e, t, a),\n          n = getParamValue(\"dtype\", e, t, a),\n          s = getParamValue(\"value\", e, t, a);\n      return [(0, _tfjsCore.fill)(r, s, n)];\n\n    case \"LinSpace\":\n      var o = getParamValue(\"start\", e, t, a),\n          p = getParamValue(\"stop\", e, t, a),\n          u = getParamValue(\"num\", e, t, a);\n      return [(0, _tfjsCore.linspace)(o, p, u)];\n\n    case \"Multinomial\":\n      var i = getParamValue(\"logits\", e, t, a),\n          m = getParamValue(\"numSamples\", e, t, a),\n          l = getParamValue(\"seed\", e, t, a);\n      return [(0, _tfjsCore.multinomial)(i, m, l)];\n\n    case \"OneHot\":\n      var c = getParamValue(\"indices\", e, t, a),\n          d = getParamValue(\"depth\", e, t, a),\n          y = getParamValue(\"onValue\", e, t, a),\n          f = getParamValue(\"offValue\", e, t, a);\n      return [(0, _tfjsCore.oneHot)(c, d, y, f)];\n\n    case \"Ones\":\n      return [(0, _tfjsCore.ones)(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"OnesLike\":\n      return [(0, _tfjsCore.onesLike)(getParamValue(\"x\", e, t, a))];\n\n    case \"RandomUniform\":\n      return [(0, _tfjsCore.randomUniform)(getParamValue(\"shape\", e, t, a), getParamValue(\"minval\", e, t, a), getParamValue(\"maxval\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"Range\":\n      o = getParamValue(\"start\", e, t, a);\n      var g = getParamValue(\"stop\", e, t, a),\n          h = getParamValue(\"step\", e, t, a);\n      return [(0, _tfjsCore.range)(o, g, h, getParamValue(\"dtype\", e, t, a))];\n\n    case \"TruncatedNormal\":\n      r = getParamValue(\"shape\", e, t, a);\n      var N = getParamValue(\"mean\", e, t, a),\n          x = getParamValue(\"stdDev\", e, t, a);\n      l = getParamValue(\"seed\", e, t, a);\n      return [(0, _tfjsCore.truncatedNormal)(r, N, x, getParamValue(\"dtype\", e, t, a), l)];\n\n    case \"Zeros\":\n      return [(0, _tfjsCore.zeros)(getParamValue(\"shape\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"ZerosLike\":\n      return [(0, _tfjsCore.zerosLike)(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    _this$1 = void 0,\n    executeOp$5 = function (e, t, a) {\n  return __awaiter(_this$1, void 0, void 0, function () {\n    var r, n, s, o, p, u, i, m;\n    return __generator(this, function (l) {\n      switch (l.label) {\n        case 0:\n          switch (e.op) {\n            case \"NonMaxSuppressionV5\":\n            case \"NonMaxSuppressionV3\":\n            case \"NonMaxSuppressionV2\":\n              return [3, 1];\n\n            case \"Where\":\n              return [3, 5];\n\n            case \"ListDiff\":\n              return [3, 7];\n          }\n\n          return [3, 8];\n\n        case 1:\n          return r = getParamValue(\"boxes\", e, t, a), n = getParamValue(\"scores\", e, t, a), s = getParamValue(\"maxOutputSize\", e, t, a), o = getParamValue(\"iouThreshold\", e, t, a), p = getParamValue(\"scoreThreshold\", e, t, a), \"NonMaxSuppressionV5\" !== e.op ? [3, 3] : (u = getParamValue(\"softNmsSigma\", e, t, a), [4, _tfjsCore.image.nonMaxSuppressionWithScoreAsync(r, n, s, o, p, u)]);\n\n        case 2:\n          return [2, [(m = l.sent()).selectedIndices, m.selectedScores]];\n\n        case 3:\n          return [4, _tfjsCore.image.nonMaxSuppressionAsync(r, n, s, o, p)];\n\n        case 4:\n          return [2, [l.sent()]];\n\n        case 5:\n          return i = getParamValue(\"condition\", e, t, a).asType(\"bool\"), [4, (0, _tfjsCore.whereAsync)(i)];\n\n        case 6:\n          return m = [l.sent()], i.dispose(), [2, m];\n\n        case 7:\n          return [2, (0, _tfjsCore.setdiff1dAsync)(getParamValue(\"x\", e, t, a), getParamValue(\"y\", e, t, a))];\n\n        case 8:\n          throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n      }\n    });\n  });\n},\n    executeOp$6 = function (e, t, a) {\n  switch (e.op) {\n    case \"TopKV2\":\n      var r = getParamValue(\"x\", e, t, a),\n          n = getParamValue(\"k\", e, t, a),\n          s = getParamValue(\"sorted\", e, t, a),\n          o = (0, _tfjsCore.topk)(r, n, s);\n      return [o.values, o.indices];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$7 = function (e, t, a) {\n  switch (e.op) {\n    case \"Const\":\n      return t[e.name];\n\n    case \"PlaceholderWithDefault\":\n      var r = getParamValue(\"default\", e, t, a);\n      return [getTensor(e.name, t, a) || r];\n\n    case \"Placeholder\":\n      return [getTensor(e.name, t, a)];\n\n    case \"Identity\":\n    case \"StopGradient\":\n    case \"FakeQuantWithMinMaxVars\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"IdentityN\":\n      return getParamValue(\"x\", e, t, a).map(function (e) {\n        return e.clone();\n      });\n\n    case \"Snapshot\":\n      return [getParamValue(\"x\", e, t, a).clone()];\n\n    case \"Shape\":\n      return [(0, _tfjsCore.tensor1d)(getParamValue(\"x\", e, t, a).shape, \"int32\")];\n\n    case \"ShapeN\":\n      return getParamValue(\"x\", e, t, a).map(function (e) {\n        return (0, _tfjsCore.tensor1d)(e.shape);\n      });\n\n    case \"Size\":\n      return [(0, _tfjsCore.scalar)(getParamValue(\"x\", e, t, a).size, \"int32\")];\n\n    case \"Rank\":\n      return [(0, _tfjsCore.scalar)(getParamValue(\"x\", e, t, a).rank, \"int32\")];\n\n    case \"NoOp\":\n      return [(0, _tfjsCore.scalar)(1)];\n\n    case \"Print\":\n      var n = getParamValue(\"x\", e, t, a),\n          s = getParamValue(\"data\", e, t, a),\n          o = getParamValue(\"message\", e, t, a),\n          p = getParamValue(\"summarize\", e, t, a);\n      console.warn(\"The graph has a tf.print() operation,usually used for debugging, which slows down performance.\"), console.log(o);\n\n      for (var u = 0; u < s.length; u++) console.log(Array.prototype.slice.call(s[u].dataSync()).slice(0, p));\n\n      return [n];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$8 = function (e, t, a) {\n  switch (e.op) {\n    case \"ResizeBilinear\":\n      var r = getParamValue(\"images\", e, t, a),\n          n = getParamValue(\"size\", e, t, a),\n          s = getParamValue(\"alignCorners\", e, t, a);\n      return [_tfjsCore.image.resizeBilinear(r, [n[0], n[1]], s)];\n\n    case \"ResizeNearestNeighbor\":\n      r = getParamValue(\"images\", e, t, a), n = getParamValue(\"size\", e, t, a), s = getParamValue(\"alignCorners\", e, t, a);\n      return [_tfjsCore.image.resizeNearestNeighbor(r, [n[0], n[1]], s)];\n\n    case \"CropAndResize\":\n      var o = getParamValue(\"image\", e, t, a),\n          p = getParamValue(\"boxes\", e, t, a),\n          u = getParamValue(\"boxInd\", e, t, a),\n          i = getParamValue(\"cropSize\", e, t, a),\n          m = getParamValue(\"method\", e, t, a),\n          l = getParamValue(\"extrapolationValue\", e, t, a);\n      return [_tfjsCore.image.cropAndResize(o, p, u, i, m, l)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$9 = function (e, t, a) {\n  switch (e.op) {\n    case \"Equal\":\n      return [(0, _tfjsCore.equal)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"NotEqual\":\n      return [(0, _tfjsCore.notEqual)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Greater\":\n      return [(0, _tfjsCore.greater)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"GreaterEqual\":\n      return [(0, _tfjsCore.greaterEqual)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Less\":\n      return [(0, _tfjsCore.less)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LessEqual\":\n      return [(0, _tfjsCore.lessEqual)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LogicalAnd\":\n      return [(0, _tfjsCore.logicalAnd)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"LogicalNot\":\n      return [(0, _tfjsCore.logicalNot)(getParamValue(\"a\", e, t, a))];\n\n    case \"LogicalOr\":\n      return [(0, _tfjsCore.logicalOr)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    case \"Select\":\n      return [(0, _tfjsCore.where)(getParamValue(\"condition\", e, t, a), getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$10 = function (e, t, a) {\n  switch (e.op) {\n    case \"BatchMatMul\":\n    case \"BatchMatMulV2\":\n    case \"MatMul\":\n      return [(0, _tfjsCore.matMul)(getParamValue(\"a\", e, t, a), getParamValue(\"b\", e, t, a), getParamValue(\"transposeA\", e, t, a), getParamValue(\"transposeB\", e, t, a))];\n\n    case \"Transpose\":\n      return [(0, _tfjsCore.transpose)(getParamValue(\"x\", e, t, a), getParamValue(\"perm\", e, t, a))];\n\n    case \"_FusedMatMul\":\n      var r = getParamValue(\"fusedOps\", e, t, a),\n          n = r[0],\n          s = r[1],\n          o = \"biasadd\" === n,\n          p = \"prelu\" === s,\n          u = getParamValue(\"numArgs\", e, t, a);\n\n      if (o) {\n        if (p && 2 !== u) throw new Error(\"Fused MatMul with BiasAdd and Prelu must have two extra arguments: bias and alpha.\");\n        if (!p && 1 !== u) throw new Error(\"Fused MatMul with BiasAdd must have one extra argument: bias.\");\n      }\n\n      var i = getParamValue(\"args\", e, t, a),\n          m = i[0],\n          l = i[1];\n      return [_tfjsCore.fused.matMul({\n        a: getParamValue(\"a\", e, t, a),\n        b: getParamValue(\"b\", e, t, a),\n        transposeA: getParamValue(\"transposeA\", e, t, a),\n        transposeB: getParamValue(\"transposeB\", e, t, a),\n        bias: m,\n        activation: s,\n        preluActivationWeights: l\n      })];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$11 = function (e, t, a) {\n  switch (e.op) {\n    case \"FusedBatchNorm\":\n    case \"FusedBatchNormV2\":\n    case \"FusedBatchNormV3\":\n      return [(0, _tfjsCore.batchNorm)(getParamValue(\"x\", e, t, a), getParamValue(\"mean\", e, t, a), getParamValue(\"variance\", e, t, a), getParamValue(\"offset\", e, t, a), getParamValue(\"scale\", e, t, a), getParamValue(\"epsilon\", e, t, a))];\n\n    case \"LRN\":\n      return [(0, _tfjsCore.localResponseNormalization)(getParamValue(\"x\", e, t, a), getParamValue(\"radius\", e, t, a), getParamValue(\"bias\", e, t, a), getParamValue(\"alpha\", e, t, a), getParamValue(\"beta\", e, t, a))];\n\n    case \"Softmax\":\n      return [(0, _tfjsCore.softmax)(getParamValue(\"x\", e, t, a))];\n\n    case \"LogSoftmax\":\n      return [(0, _tfjsCore.logSoftmax)(getParamValue(\"x\", e, t, a))];\n\n    case \"SparseToDense\":\n      return [(0, _tfjsCore.sparseToDense)(getParamValue(\"sparseIndices\", e, t, a), getParamValue(\"outputShape\", e, t, a), getParamValue(\"sparseValues\", e, t, a), getParamValue(\"defaultValue\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$12 = function (e, t, a) {\n  switch (e.op) {\n    case \"Max\":\n      var r = getParamValue(\"axis\", e, t, a),\n          n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.max)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Mean\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.mean)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Min\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.min)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Sum\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.sum)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"All\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.all)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"Any\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.any)(getParamValue(\"x\", e, t, a), r, n)];\n\n    case \"ArgMax\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [(0, _tfjsCore.argMax)(getParamValue(\"x\", e, t, a), r)];\n\n    case \"ArgMin\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [(0, _tfjsCore.argMin)(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Prod\":\n      r = getParamValue(\"axis\", e, t, a), n = getParamValue(\"keepDims\", e, t, a);\n      return [(0, _tfjsCore.prod)(getParamValue(\"x\", e, t, a), r, n)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$13 = function (e, t, a) {\n  switch (e.op) {\n    case \"ConcatV2\":\n    case \"Concat\":\n      var r = getParamValue(\"n\", e, t, a),\n          n = getParamValue(\"axis\", e, t, a),\n          s = getParamValue(\"tensors\", e, t, a);\n      return s = s.slice(0, r), [(0, _tfjsCore.concat)(s, n)];\n\n    case \"GatherV2\":\n    case \"Gather\":\n      n = getParamValue(\"axis\", e, t, a);\n      var o = getParamValue(\"x\", e, t, a),\n          p = getParamValue(\"indices\", e, t, a);\n      return [(0, _tfjsCore.gather)(o, p.asType(\"int32\"), n)];\n\n    case \"ReverseV2\":\n    case \"Reverse\":\n      n = getParamValue(\"axis\", e, t, a), o = getParamValue(\"x\", e, t, a);\n      return [(0, _tfjsCore.reverse)(o, n)];\n\n    case \"Slice\":\n      var u = getParamValue(\"begin\", e, t, a),\n          i = getParamValue(\"size\", e, t, a);\n      return [(0, _tfjsCore.slice)(getParamValue(\"x\", e, t, a), u, i)];\n\n    case \"StridedSlice\":\n      u = getParamValue(\"begin\", e, t, a);\n      var m = getParamValue(\"end\", e, t, a),\n          l = getParamValue(\"strides\", e, t, a),\n          c = getParamValue(\"beginMask\", e, t, a),\n          d = getParamValue(\"endMask\", e, t, a),\n          y = getParamValue(\"ellipsisMask\", e, t, a),\n          f = getParamValue(\"newAxisMask\", e, t, a),\n          g = getParamValue(\"shrinkAxisMask\", e, t, a),\n          h = getParamValue(\"x\", e, t, a);\n      if (1 === u.length && h.shape.length > 1) for (var N = 1; N < h.shape.length; N++) u.push(0), m.push(h.shape[N]), l.push(l[0]);\n      return [(0, _tfjsCore.stridedSlice)(h, u, m, l, c, d, y, f, g)];\n\n    case \"Pack\":\n      return (0, _tfjsCore.tidy)(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensors\", e, t, a),\n            s = n[0].shape,\n            o = n[0].squeeze().shape,\n            p = n.map(function (e) {\n          var t = _tfjsCore.util.arraysEqual(e.shape, s);\n\n          if (!t && !_tfjsCore.util.arraysEqual(e.squeeze().shape, o)) throw new Error(\"the input tensors shape does not match\");\n          return t ? e : e.reshape(s);\n        });\n        return [(0, _tfjsCore.stack)(p, r)];\n      });\n\n    case \"Unpack\":\n      return (0, _tfjsCore.tidy)(function () {\n        var r = getParamValue(\"axis\", e, t, a),\n            n = getParamValue(\"tensor\", e, t, a);\n        return (0, _tfjsCore.unstack)(n, r);\n      });\n\n    case \"Tile\":\n      var x = getParamValue(\"reps\", e, t, a);\n      return [(0, _tfjsCore.tile)(getParamValue(\"x\", e, t, a), x)];\n\n    case \"Split\":\n    case \"SplitV\":\n      n = getParamValue(\"axis\", e, t, a);\n      var V = getParamValue(\"numOrSizeSplits\", e, t, a);\n      return (0, _tfjsCore.split)(getParamValue(\"x\", e, t, a), V, n);\n\n    case \"ScatterNd\":\n      p = getParamValue(\"indices\", e, t, a);\n      var b = getParamValue(\"values\", e, t, a),\n          P = getParamValue(\"shape\", e, t, a);\n      return [(0, _tfjsCore.scatterND)(p, b, P)];\n\n    case \"GatherNd\":\n      var T = getParamValue(\"x\", e, t, a);\n      p = getParamValue(\"indices\", e, t, a);\n      return [(0, _tfjsCore.gatherND)(T, p)];\n\n    case \"SparseToDense\":\n      p = getParamValue(\"sparseIndices\", e, t, a), P = getParamValue(\"outputShape\", e, t, a);\n      var v = getParamValue(\"sparseValues\", e, t, a),\n          O = getParamValue(\"defaultValue\", e, t, a);\n      return [(0, _tfjsCore.sparseToDense)(p, v, P, v.dtype === O.dtype ? O : O.asType(v.dtype))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$14 = function (e, t, a) {\n  switch (e.op) {\n    case \"FFT\":\n      return [(0, _tfjsCore.fft)(getParamValue(\"x\", e, t, a))];\n\n    case \"IFFT\":\n      return [(0, _tfjsCore.ifft)(getParamValue(\"x\", e, t, a))];\n\n    case \"RFFT\":\n      return [(0, _tfjsCore.rfft)(getParamValue(\"x\", e, t, a))];\n\n    case \"IRFFT\":\n      return [(0, _tfjsCore.irfft)(getParamValue(\"x\", e, t, a))];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n},\n    executeOp$15 = function (e, t, a) {\n  switch (e.op) {\n    case \"Cast\":\n      return [(0, _tfjsCore.cast)(getParamValue(\"x\", e, t, a), getParamValue(\"dtype\", e, t, a))];\n\n    case \"ExpandDims\":\n      var r = getParamValue(\"axis\", e, t, a);\n      return [(0, _tfjsCore.expandDims)(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Squeeze\":\n      r = getParamValue(\"axis\", e, t, a);\n      return [(0, _tfjsCore.squeeze)(getParamValue(\"x\", e, t, a), r)];\n\n    case \"Reshape\":\n      return [(0, _tfjsCore.reshape)(getParamValue(\"x\", e, t, a), getParamValue(\"shape\", e, t, a))];\n\n    case \"PadV2\":\n    case \"Pad\":\n      return [(0, _tfjsCore.pad)(getParamValue(\"x\", e, t, a), split$1(getParamValue(\"padding\", e, t, a), 2), getParamValue(\"constantValue\", e, t, a))];\n\n    case \"SpaceToBatchND\":\n      var n = getParamValue(\"blockShape\", e, t, a),\n          s = split$1(getParamValue(\"paddings\", e, t, a), 2);\n      return [(0, _tfjsCore.spaceToBatchND)(getParamValue(\"x\", e, t, a), n, s)];\n\n    case \"BatchToSpaceND\":\n      n = getParamValue(\"blockShape\", e, t, a);\n      var o = split$1(getParamValue(\"crops\", e, t, a), 2);\n      return [(0, _tfjsCore.batchToSpaceND)(getParamValue(\"x\", e, t, a), n, o)];\n\n    case \"DepthToSpace\":\n      var p = getParamValue(\"blockSize\", e, t, a),\n          u = getParamValue(\"dataFormat\", e, t, a).toUpperCase();\n      return [(0, _tfjsCore.depthToSpace)(getParamValue(\"x\", e, t, a), p, u)];\n\n    default:\n      throw TypeError(\"Node type \" + e.op + \" is not implemented\");\n  }\n};\n\nfunction executeOp$16(e, t, a) {\n  var r = function (e, t, a) {\n    switch (e.category) {\n      case \"arithmetic\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp(e, t, a);\n        });\n\n      case \"basic_math\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$1(e, t, a);\n        });\n\n      case \"control\":\n        return executeOp$2(e, t, a);\n\n      case \"convolution\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$3(e, t, a);\n        });\n\n      case \"creation\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$4(e, t, a);\n        });\n\n      case \"dynamic\":\n        return executeOp$5(e, t, a);\n\n      case \"evaluation\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$6(e, t, a);\n        });\n\n      case \"image\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$8(e, t, a);\n        });\n\n      case \"graph\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$7(e, t, a);\n        });\n\n      case \"logical\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$9(e, t, a);\n        });\n\n      case \"matrices\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$10(e, t, a);\n        });\n\n      case \"normalization\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$11(e, t, a);\n        });\n\n      case \"reduction\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$12(e, t, a);\n        });\n\n      case \"slice_join\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$13(e, t, a);\n        });\n\n      case \"spectral\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$14(e, t, a);\n        });\n\n      case \"transformation\":\n        return (0, _tfjsCore.tidy)(function () {\n          return executeOp$15(e, t, a);\n        });\n\n      case \"custom\":\n        var r = getRegisteredOp(e.op);\n        if (r && r.customExecutor) return r.customExecutor(new NodeValueImpl(e, t, a));\n        throw TypeError(\"Custom op \" + e.op + \" is not registered.\");\n\n      default:\n        throw TypeError(\"Unknown op '\" + e.op + \"'. File an issue at https://github.com/tensorflow/tfjs/issues so we can add it, or register a custom execution with tf.registerOp()\");\n    }\n  }(e, t, a);\n\n  return r instanceof Promise ? r.then(function (e) {\n    return [].concat(e);\n  }) : [].concat(r);\n}\n\nvar ExecutionContext = function () {\n  function e(e, t) {\n    this.weightMap = e, this.tensorArrayMap = t, this.rootContext = {\n      id: 0,\n      frameName: \"\",\n      iterationId: 0\n    }, this.contexts = [this.rootContext], this.lastId = 0, this.generateCurrentContextIds();\n  }\n\n  return e.prototype.newFrame = function (e, t) {\n    return {\n      id: e,\n      frameName: t,\n      iterationId: 0\n    };\n  }, Object.defineProperty(e.prototype, \"currentContext\", {\n    get: function () {\n      return this.contexts;\n    },\n    set: function (e) {\n      this.contexts !== e && (this.contexts = e, this.generateCurrentContextIds());\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextId\", {\n    get: function () {\n      return this._currentContextIds[0];\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"currentContextIds\", {\n    get: function () {\n      return this._currentContextIds;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.generateCurrentContextIds = function () {\n    for (var e = [], t = 0; t < this.contexts.length - 1; t++) {\n      var a = this.contexts.slice(0, this.contexts.length - t);\n      e.push(this.contextIdforContexts(a));\n    }\n\n    e.push(\"\"), this._currentContextIds = e;\n  }, e.prototype.contextIdforContexts = function (e) {\n    return e ? e.map(function (e) {\n      return 0 === e.id && 0 === e.iterationId ? \"\" : e.frameName + \"-\" + e.iterationId;\n    }).join(\"/\") : \"\";\n  }, e.prototype.enterFrame = function (e) {\n    this.contexts && (this.lastId++, this.contexts = this.contexts.slice(), this.contexts.push(this.newFrame(this.lastId, e)), this._currentContextIds.unshift(this.contextIdforContexts(this.contexts)));\n  }, e.prototype.exitFrame = function () {\n    if (!(this.contexts && this.contexts.length > 1)) throw new Error(\"Cannot exit frame, the context is empty\");\n    this.contexts = this.contexts.slice(), this.contexts.splice(-1), this.currentContextIds.shift();\n  }, e.prototype.nextIteration = function () {\n    if (!(this.contexts && this.contexts.length > 0)) throw new Error(\"Cannot increase frame iteration, the context is empty\");\n    this.contexts = this.contexts.slice(), this.lastId++;\n    var e = Object.assign({}, this.contexts[this.contexts.length - 1]);\n    e.iterationId += 1, e.id = this.lastId, this.contexts.splice(-1, 1, e), this._currentContextIds.splice(0, 1, this.contextIdforContexts(this.contexts));\n  }, e.prototype.getWeight = function (e) {\n    return this.weightMap[e];\n  }, e.prototype.addTensorArray = function (e) {\n    this.tensorArrayMap[e.id] = e;\n  }, e.prototype.getTensorArray = function (e) {\n    return this.tensorArrayMap[e];\n  }, e;\n}();\n\nfunction getExecutionSubgraph(e, t, a) {\n  for (var r = new Set(), n = [], s = null, o = null, p = new Set(), u = Object.keys(e).map(function (e) {\n    return parseNodeName(e)[0];\n  }), i = t.slice(); i.length > 0;) {\n    var m = i.pop();\n    (isControlFlow(m) || isDynamicShape(m)) && null == s && (o = (s = m).children.map(function (e) {\n      return e.name;\n    }).filter(function (e) {\n      return r.has(e);\n    })), r.add(m.name), null == a[m.name] && -1 === u.indexOf(m.name) && (0 !== m.inputs.length ? m.inputs.forEach(function (e) {\n      p.has(e.name) || (p.add(e.name), i.push(e));\n    }) : n.push(m.name));\n  }\n\n  return {\n    inputs: e,\n    outputs: t,\n    usedNodes: r,\n    missingInputs: n,\n    dynamicNode: s,\n    syncInputs: o\n  };\n}\n\nfunction getNodesInTopologicalOrder(e, t, a) {\n  var r = a.usedNodes,\n      n = a.inputs,\n      s = [];\n  Object.keys(n).map(function (e) {\n    return parseNodeName(e)[0];\n  }).map(function (t) {\n    return e.nodes[t];\n  }).forEach(function (e) {\n    r.has(e.name) && s.push(e);\n  }), e.weights.forEach(function (e) {\n    r.has(e.name) && s.push(e);\n  });\n\n  for (var o = new Set(), p = []; s.length > 0;) {\n    var u = s.pop();\n    o.add(u.name), t[u.name] || p.push(u), u.children.forEach(function (e) {\n      !o.has(e.name) && r.has(e.name) && e.inputs.every(function (e) {\n        return o.has(e.name);\n      }) && s.push(e);\n    });\n  }\n\n  return p;\n}\n\nvar CONTROL_FLOW_OPS = [\"Switch\", \"Merge\", \"Enter\", \"Exit\", \"NextIteration\"],\n    DYNAMIC_SHAPE_OPS = [\"NonMaxSuppressionV2\", \"NonMaxSuppressionV3\", \"NonMaxSuppressionV5\", \"Where\"];\n\nfunction isControlFlow(e) {\n  return CONTROL_FLOW_OPS.indexOf(e.op) >= 0;\n}\n\nfunction isDynamicShape(e) {\n  return DYNAMIC_SHAPE_OPS.indexOf(e.op) >= 0;\n}\n\nvar GraphExecutor = function () {\n  function e(e) {\n    this.graph = e, this.compiledMap = new Map(), this._weightMap = {}, this.SEPERATOR = \",\", this._outputs = e.outputs, this._inputs = e.inputs, this._signature = e.signature;\n  }\n\n  return Object.defineProperty(e.prototype, \"weightMap\", {\n    get: function () {\n      return this._weightMap;\n    },\n    set: function (e) {\n      var t = Object.keys(e).map(function (t) {\n        return e[t].map(function (e) {\n          return e.id;\n        });\n      });\n      this.weightIds = [].concat.apply([], t), this._weightMap = e;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function () {\n      return this._inputs.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,\n          dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function () {\n      return this._outputs.map(function (e) {\n        return {\n          name: e.name,\n          shape: e.attrParams.shape ? e.attrParams.shape.value : void 0,\n          dtype: e.attrParams.dtype ? e.attrParams.dtype.value : void 0\n        };\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function () {\n      return this._inputs.map(function (e) {\n        return e.signatureKey || e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function () {\n      return this._outputs.map(function (e) {\n        return e.signatureKey || e.name;\n      });\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.getCompilationKey = function (e, t) {\n    var a = e.map(function (e) {\n      return e.name;\n    }).sort(),\n        r = t.map(function (e) {\n      return e.name;\n    }).sort();\n    return a.join(this.SEPERATOR) + \"--\" + r.join(this.SEPERATOR);\n  }, e.prototype.compile = function (e, t) {\n    var a = getExecutionSubgraph(e, t, this.weightMap),\n        r = a.missingInputs,\n        n = a.dynamicNode,\n        s = a.syncInputs;\n    if (null != n) throw new Error(\"This execution contains the node '\" + n.name + \"', which has the dynamic op '\" + n.op + \"'. Please use model.executeAsync() instead. Alternatively, to avoid the dynamic ops, specify the inputs [\" + s + \"]\");\n\n    if (r.length > 0) {\n      var o = t.map(function (e) {\n        return e.name;\n      }),\n          p = Object.keys(e);\n      throw new Error(\"Cannot compute the outputs [\" + o + \"] from the provided inputs [\" + p + \"]. Missing the following inputs: [\" + r + \"]\");\n    }\n\n    return getNodesInTopologicalOrder(this.graph, this.weightMap, a);\n  }, e.prototype.execute = function (e, t) {\n    var a = this;\n    e = this.mapInputs(e);\n    var r = Object.keys(e).sort();\n    this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t);\n    var n = r.map(function (e) {\n      return a.graph.nodes[parseNodeName(e)[0]];\n    }),\n        s = t.map(function (e) {\n      return a.graph.nodes[parseNodeName(e)[0]];\n    }),\n        o = this.getCompilationKey(n, s),\n        p = this.compiledMap.get(o);\n    null == p && (p = this.compile(e, s), this.compiledMap.set(o, p));\n    var u = {};\n    return (0, _tfjsCore.tidy)(function () {\n      var r = new ExecutionContext(a._weightMap, u),\n          n = __assign({}, a.weightMap);\n\n      Object.keys(e).forEach(function (t) {\n        var a = parseNodeName(t),\n            r = a[0],\n            s = [];\n        s[a[1]] = e[t], n[r] = s;\n      });\n\n      for (var s = a.getFrozenTensorIds(n), o = {}, i = 0; i < p.length; i++) {\n        var m = p[i];\n\n        if (!n[m.name]) {\n          var l = executeOp$16(m, n, r);\n          if (l instanceof Promise) throw new Error(\"The execution of the op '\" + m.op + \"' returned a promise. Please use model.executeAsync() instead.\");\n          n[m.name] = l, a.checkTensorForDisposal(m.name, m, n, r, s, t, o);\n        }\n      }\n\n      return t.map(function (e) {\n        return getTensor(e, n, r);\n      });\n    });\n  }, e.prototype.getFrozenTensorIds = function (e) {\n    var t = [].concat.apply([], Object.keys(e).map(function (t) {\n      return e[t];\n    }).map(function (e) {\n      return e.map(function (e) {\n        return e.id;\n      });\n    }));\n    return new Set(t);\n  }, e.prototype.checkTensorForDisposal = function (e, t, a, r, n, s, o) {\n    \"control\" !== t.category && -1 === s.indexOf(e) && (a[e].forEach(function (e) {\n      null != e && (o[e.id] = (o[e.id] || 0) + t.children.length);\n    }), t.inputs.forEach(function (e) {\n      if (\"control\" !== e.category) {\n        var t = getTensorsForCurrentContenxt(e.name, a, r);\n        null != t && t.forEach(function (e) {\n          if (e && !n.has(e.id)) {\n            var t = o[e.id];\n            1 === t ? (e.dispose(), delete o[e.id]) : null != t && o[e.id]--;\n          }\n        });\n      }\n    }));\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a,\n          r,\n          n,\n          s,\n          o,\n          p,\n          u = this;\n      return __generator(this, function (i) {\n        switch (i.label) {\n          case 0:\n            return e = this.mapInputs(e), this.checkInputs(e), this.checkInputShapeAndType(e), t = this.mapOutputs(t), this.checkOutputs(t), a = {}, r = new ExecutionContext(this._weightMap, a), [4, this.executeWithControlFlow(e, r, t)];\n\n          case 1:\n            return n = i.sent(), s = t.map(function (e) {\n              return getTensor(e, n, r);\n            }), o = new Set(s.map(function (e) {\n              return e.id;\n            })), p = new Set(Object.keys(e).map(function (t) {\n              return e[t].id;\n            })), Object.keys(n).forEach(function (e) {\n              n[e].forEach(function (e) {\n                !e || e.isDisposed || o.has(e.id) || p.has(e.id) || -1 !== u.weightIds.indexOf(e.id) || e.dispose();\n              });\n            }), [2, s];\n        }\n      });\n    });\n  }, e.prototype.executeWithControlFlow = function (e, t, a) {\n    return __awaiter(this, void 0, void 0, function () {\n      var r,\n          n,\n          s,\n          o,\n          p,\n          u,\n          i,\n          m,\n          l,\n          c,\n          d,\n          y,\n          f,\n          g,\n          h,\n          N,\n          x = this;\n      return __generator(this, function (V) {\n        switch (V.label) {\n          case 0:\n            r = Object.keys(e), n = r.map(function (e) {\n              return x.graph.nodes[parseNodeName(e)[0]];\n            }), s = a.map(function (e) {\n              return x.graph.nodes[parseNodeName(e)[0]];\n            }), o = getExecutionSubgraph(e, s, this.weightMap), p = o.usedNodes, u = o.missingInputs, i = o.dynamicNode, m = o.syncInputs, l = n.concat(this.graph.weights).map(function (e) {\n              return {\n                node: e,\n                contexts: t.currentContext\n              };\n            }), c = __assign({}, this.weightMap), Object.keys(e).forEach(function (t) {\n              var a = parseNodeName(t),\n                  r = a[0],\n                  n = [];\n              n[a[1]] = e[t], c[r] = n;\n            }), d = {}, y = this.getFrozenTensorIds(c), f = {}, V.label = 1;\n\n          case 1:\n            return l.length > 0 ? (g = this.processStack(n, l, t, c, f, y, a, d, p), [4, Promise.all(g)]) : [3, 3];\n\n          case 2:\n            return V.sent(), [3, 1];\n\n          case 3:\n            if (null == i && console.warn(\"This model execution did not contain any nodes with control flow or dynamic output shapes. You can use model.execute() instead.\"), (h = s.filter(function (e) {\n              return !isControlFlow(e) && !getTensor(e.name, c, t);\n            }).map(function (e) {\n              return e.name;\n            })).length > 0) throw N = \"\", null != i && (N = \"Alternatively, to avoid the dynamic ops, use model.execute() and specify the inputs [\" + m + \"]\"), new Error(\"Cannot compute the outputs [\" + h + \"] from the provided inputs [\" + r + \"]. Consider providing the following inputs: [\" + u + \"]. \" + N);\n            return [2, c];\n        }\n      });\n    });\n  }, e.prototype.processStack = function (e, t, a, r, n, s, o, p, u) {\n    for (var i = this, m = [], l = function () {\n      var l = t.pop();\n      a.currentContext = l.contexts;\n      var d = \"\";\n\n      if (\"Enter\" === l.node.op && getParamValue(\"isConstant\", l.node, r, a) && (d = getNodeNameAndIndex(l.node.name, a)[0]), -1 === e.indexOf(l.node)) {\n        var y = executeOp$16(l.node, r, a);\n        d || (d = getNodeNameAndIndex(l.node.name, a)[0]);\n        var f = a.currentContext;\n        y instanceof Promise ? m.push(y.then(function (e) {\n          return r[d] = e, a.currentContext = f, i.checkTensorForDisposal(d, l.node, r, a, s, o, p), i.processChildNodes(l.node, t, a, r, n, u), e;\n        })) : (r[d] = y, c.checkTensorForDisposal(d, l.node, r, a, s, o, p), c.processChildNodes(l.node, t, a, r, n, u));\n      } else c.processChildNodes(l.node, t, a, r, n, u);\n    }, c = this; t.length > 0;) l();\n\n    return m;\n  }, e.prototype.processChildNodes = function (e, t, a, r, n, s) {\n    e.children.forEach(function (e) {\n      var o = getNodeNameAndIndex(e.name, a)[0];\n      !n[o] && s.has(e.name) && (\"Merge\" === e.op ? e.inputNames.some(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })) : e.inputNames.every(function (e) {\n        return !!getTensor(e, r, a);\n      }) && (n[o] = !0, t.push({\n        contexts: a.currentContext,\n        node: e\n      })));\n    });\n  }, e.prototype.dispose = function () {\n    var e = this;\n    Object.keys(this.weightMap).forEach(function (t) {\n      return e.weightMap[t].forEach(function (e) {\n        return e.dispose();\n      });\n    });\n  }, e.prototype.checkInputShapeAndType = function (e) {\n    var t = this;\n    Object.keys(e).forEach(function (a) {\n      var r = e[a],\n          n = parseNodeName(a)[0],\n          s = t.graph.nodes[n];\n\n      if (s.attrParams.shape && s.attrParams.shape.value) {\n        var o = s.attrParams.shape.value,\n            p = o.length === r.shape.length && r.shape.every(function (e, t) {\n          return -1 === o[t] || o[t] === e;\n        });\n\n        _tfjsCore.util.assert(p, function () {\n          return \"The shape of dict['\" + s.name + \"'] provided in model.execute(dict) must be [\" + o + \"], but was [\" + r.shape + \"]\";\n        });\n      }\n\n      s.attrParams.dtype && s.attrParams.dtype.value && _tfjsCore.util.assert(r.dtype === s.attrParams.dtype.value, function () {\n        return \"The dtype of dict['\" + s.name + \"'] provided in model.execute(dict) must be \" + s.attrParams.dtype.value + \", but was \" + r.dtype;\n      });\n    });\n  }, e.prototype.mapInputs = function (e) {\n    var t = {};\n\n    for (var a in e) {\n      if (null != this._signature && null != this._signature.inputs && null != this._signature.inputs[a]) t[this._signature.inputs[a].name] = e[a];else t[a] = e[a];\n    }\n\n    return t;\n  }, e.prototype.checkInputs = function (e) {\n    var t = this,\n        a = Object.keys(e).filter(function (e) {\n      var a = parseNodeName(e)[0];\n      return null == t.graph.nodes[a];\n    });\n    if (a.length > 0) throw new Error(\"The dict provided in model.execute(dict) has keys: [\" + a + \"] that are not part of graph\");\n  }, e.prototype.mapOutputs = function (e) {\n    var t = this;\n    return e.map(function (e) {\n      return null != t._signature && null != t._signature.outputs && null != t._signature.outputs[e] ? t._signature.outputs[e].name : e;\n    }, {});\n  }, e.prototype.checkOutputs = function (e) {\n    var t = this;\n    e.forEach(function (e) {\n      var a = parseNodeName(e)[0];\n      if (!t.graph.nodes[a]) throw new Error(\"The output '\" + e + \"' is not found in the graph\");\n    });\n  }, e;\n}(),\n    TFHUB_SEARCH_PARAM = \"?tfjs-format=file\",\n    DEFAULT_MODEL_NAME = \"model.json\",\n    GraphModel = function () {\n  function e(e, t) {\n    void 0 === t && (t = {}), this.modelUrl = e, this.loadOptions = t, this.version = \"n/a\", null == t && (this.loadOptions = {});\n  }\n\n  return Object.defineProperty(e.prototype, \"modelVersion\", {\n    get: function () {\n      return this.version;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputNodes\", {\n    get: function () {\n      return this.executor.inputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputNodes\", {\n    get: function () {\n      return this.executor.outputNodes;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"inputs\", {\n    get: function () {\n      return this.executor.inputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"outputs\", {\n    get: function () {\n      return this.executor.outputs;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), Object.defineProperty(e.prototype, \"weights\", {\n    get: function () {\n      return this.executor.weightMap;\n    },\n    enumerable: !0,\n    configurable: !0\n  }), e.prototype.findIOHandler = function () {\n    var e = this.modelUrl;\n    if (null != e.load) this.handler = e;else if (null != this.loadOptions.requestInit) this.handler = _tfjsCore.io.browserHTTPRequest(e, this.loadOptions);else {\n      var t = _tfjsCore.io.getLoadHandlers(e, this.loadOptions.onProgress);\n\n      if (0 === t.length) t.push(_tfjsCore.io.browserHTTPRequest(e, this.loadOptions));else if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") load handlers for URL '\" + [e] + \"'\");\n      this.handler = t[0];\n    }\n  }, e.prototype.load = function () {\n    return __awaiter(this, void 0, void 0, function () {\n      var e, t, a, r;\n      return __generator(this, function (n) {\n        switch (n.label) {\n          case 0:\n            if (this.findIOHandler(), null == this.handler.load) throw new Error(\"Cannot proceed with model loading because the IOHandler provided does not have the `load` method implemented.\");\n            return e = this, [4, this.handler.load()];\n\n          case 1:\n            return e.artifacts = n.sent(), t = this.artifacts.modelTopology, a = {}, null != this.artifacts.userDefinedMetadata && (a = this.artifacts.userDefinedMetadata.signature), this.version = t.versions.producer + \".\" + t.versions.minConsumer, r = _tfjsCore.io.decodeWeights(this.artifacts.weightData, this.artifacts.weightSpecs), this.executor = new GraphExecutor(OperationMapper.Instance.transformGraph(t, a)), this.executor.weightMap = this.convertTensorMapToTensorsMap(r), [2, !0];\n        }\n      });\n    });\n  }, e.prototype.save = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var t;\n      return __generator(this, function (a) {\n        if (\"string\" == typeof e) {\n          if (0 === (t = _tfjsCore.io.getSaveHandlers(e)).length) throw new Error(\"Cannot find any save handlers for URL '\" + e + \"'\");\n          if (t.length > 1) throw new Error(\"Found more than one (\" + t.length + \") save handlers for URL '\" + e + \"'\");\n          e = t[0];\n        }\n\n        if (null == e.save) throw new Error(\"GraphModel.save() cannot proceed because the IOHandler provided does not have the `save` attribute defined.\");\n        return [2, e.save(this.artifacts)];\n      });\n    });\n  }, e.prototype.predict = function (e, t) {\n    return this.execute(e, this.outputNodes);\n  }, e.prototype.normalizeInputs = function (e) {\n    if (!(e instanceof _tfjsCore.Tensor || Array.isArray(e))) return e;\n    if ((e = Array.isArray(e) ? e : [e]).length !== this.inputNodes.length) throw new Error(\"Input tensor count mismatch,the graph model has \" + this.inputNodes.length + \" placeholders, while there are \" + e.length + \" input tensors.\");\n    return this.inputNodes.reduce(function (t, a, r) {\n      return t[a] = e[r], t;\n    }, {});\n  }, e.prototype.normalizeOutputs = function (e) {\n    return e = e || this.outputNodes, Array.isArray(e) ? e : [e];\n  }, e.prototype.execute = function (e, t) {\n    e = this.normalizeInputs(e), t = this.normalizeOutputs(t);\n    var a = this.executor.execute(e, t);\n    return a.length > 1 ? a : a[0];\n  }, e.prototype.executeAsync = function (e, t) {\n    return __awaiter(this, void 0, void 0, function () {\n      var a;\n      return __generator(this, function (r) {\n        switch (r.label) {\n          case 0:\n            return e = this.normalizeInputs(e), t = this.normalizeOutputs(t), [4, this.executor.executeAsync(e, t)];\n\n          case 1:\n            return [2, (a = r.sent()).length > 1 ? a : a[0]];\n        }\n      });\n    });\n  }, e.prototype.convertTensorMapToTensorsMap = function (e) {\n    return Object.keys(e).reduce(function (t, a) {\n      return t[a] = [e[a]], t;\n    }, {});\n  }, e.prototype.dispose = function () {\n    this.executor.dispose();\n  }, e;\n}();\n\nexports.GraphModel = GraphModel;\n\nfunction loadGraphModel(e, t) {\n  return void 0 === t && (t = {}), __awaiter(this, void 0, void 0, function () {\n    var a;\n    return __generator(this, function (r) {\n      switch (r.label) {\n        case 0:\n          if (null == e) throw new Error(\"modelUrl in loadGraphModel() cannot be null. Please provide a url or an IOHandler that loads the model\");\n          return null == t && (t = {}), t.fromTFHub && null == e.load && (e.endsWith(\"/\") || (e += \"/\"), e = \"\" + e + DEFAULT_MODEL_NAME + TFHUB_SEARCH_PARAM), [4, (a = new GraphModel(e, t)).load()];\n\n        case 1:\n          return r.sent(), [2, a];\n      }\n    });\n  });\n}\n\nvar version = \"1.7.1\";\nexports.version_converter = version;"},"sourceMaps":null,"error":null,"hash":"d9e1623108eb2f0496f3c82cc8c2705b","cacheData":{"env":{}}}